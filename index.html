---
layout: page
description: "My Homepage"
motto: "Research for a better world."
---
<hr>
<p style="margin-top:15px; line-height:1.5; text-align:justify; text-justify:inter-ideograph;">
<font size=4>
<span style="color:black;">

I'm Yanwei Li (<span style="font-family: KaiTi_GB2312;">李彦玮</span>), currently working as a Research Scientist on Foundation Model for Vision & Language at ByteDance Seed, San Jose, USA.<br/><br/>

Before that, I obtained Ph.D degree in The Chinese University of Hong Kong (CUHK), supervised by Prof. 
<a href="http://jiaya.me/" style="color:rgb(51, 156, 255)">Jiaya Jia</a>.<br/><br/>

Previously, I spent wonderful time in NVIDIA, MEGVII, Horizon Robotics, and IBM Research. During these periods, I was fortunate to collaborate with several top researchers like Prof. 
<a href="http://tensorlab.cms.caltech.edu/users/anima/" style="color:rgb(51, 156, 255)">Anima Anandkumar</a> (CalTech), Prof. 
<a href="https://www.cs.utoronto.ca/~fidler/" style="color:rgb(51, 156, 255)">Sanja Fidler</a> (UofT), and Dr. 
<a href="https://scholar.google.com/citations?user=ALVSZAYAAAAJ&hl=en" style="color:rgb(51, 156, 255)">Jian Sun</a>.<br/><br/>

My research interests mainly focus on Multi-modality Foundation Model and Generative AI. My recent work includes 
<a href="https://arxiv.org/abs/2505.07062" style="color:rgb(51, 156, 255)">Seed 1.5-VL</a>, 
<a href="https://arxiv.org/pdf/2408.03326?" style="color:rgb(51, 156, 255)">LLaVA-OneVision</a>, 
<a href="https://arxiv.org/pdf/2403.18814.pdf" style="color:rgb(51, 156, 255)">Mini-Gemini</a>, 
<a href="https://arxiv.org/pdf/2311.17043.pdf" style="color:rgb(51, 156, 255)">LLaMA-VID</a>, 
<a href="https://arxiv.org/pdf/2308.00692" style="color:rgb(51, 156, 255)">LISA</a>, and 
<a href="https://arxiv.org/abs/2405.21075" style="color:rgb(51, 156, 255)">Video-MME</a>.<br/><br/>

More experiences about me please refer to 
<a href="/publication/" style="color:rgb(51, 156, 255)"><b>Publication</b></a> and my 
<a href="https://scholar.google.com/citations?user=I-UCPPcAAAAJ&hl=zh-CN&oi=ao" style="color:rgb(51, 156, 255)"><b>Google Scholar</b></a>.

</span>
</font>
</p>
<hr/>

<!-- <hr>
<h2> Education</h2>
<p style = "margin-top:15px">
    <font size=4>
        <b><span style="color:black">The Chinese University of Hong Kong</span></b><br/>
    </font>
    <b>Fields: Computer Vision</b><br/>
    <i>Ph.D, Computer Science and Engineering, 2020 - 2024.</i>
</p>

<p style = "margin-top:15px">
<font size=4>
    <b><span style="color:black">Institute of Automation, Chinese Academy of Sciences</span></b><br/>
</font>
<b>Fields: Computer Vision</b><br/>
<i>M.Phil, Pattern Recognition and Intelligent System, 2017 - 2020.</i>
</p>

<p style = "margin-top:5px">
<font size=4>
    <b><span style="color:black">Central South University</span></b><br/>
</font>
<i>B.E., Automation & Mechanical Engineering, 2013 - 2017.</i>
</p> -->
<hr>

<h2> Experience</h2>
<p style = "margin-top:15px">
<font size=4>
    <b><span style="color:black">ByteDance Seed</span></b><br/>
</font>
<b>Fields: Multimodal Foundation Model.</b><br/>
<i>Research Scientist, 2024.09 - Now</i><br/>
</p>

<p style = "margin-top:15px">
<font size=4>
    <b><span style="color:black">NVIDIA Research</span></b><br/>
</font>
<b>Fields: Multimodal Perception.</b><br/>
<i>Research Intern, 2022.06 - 2023.04</i><br/>
</p>

<p style = "margin-top:15px">
<font size=4>
    <b><span style="color:black">MEGVII</span></b><br/>
</font>
<b>Fields: 2D & 3D Perception.</b><br/>
<i>Research Intern, 2019.01 - 2022.05</i><br/>
</p>

<!-- <p style = "margin-top:5px">
<font size=4>
    <b><span style="color:black">Horizon Robotics</span></b><br/>
</font>
<b>Fields: 2D Perception.</b><br/>
<i>Research Intern, 2018.04 - 2018.12</i><br/>
</p>

<p style = "margin-top:5px">
<font size=4>
    <b><span style="color:black">IBM Research</span></b><br/>
</font>
<b>Fields:2D Perception.</b><br/>
<i>Research Intern, 2017.08 - 2018.01</i><br/>
</p> -->
<hr>

<h2> Service</h2>
<p style = "margin-top:15px">
<font size=4>
<span style="color:black">
    <b>Area Chair:</b><br/>
    Neural Information Processing Systems (NeurIPS), 2025.<br/>
</p>
    <b>Conference Reviewer:</b><br/>
    International Conference on Learning Representations (ICLR).<br/>
    International Conference on Machine Learning (ICML).<br/>
    Neural Information Processing Systems (NeurIPS).<br/>
    IEEE Conference on Computer Vision and Pattern Recognition (CVPR).<br/>
    IEEE International Conference on Computer Vision (ICCV).<br/>
    European Conference on Computer Vision (ECCV).<br/>
    AAAI Conference on Artificial Intelligence (AAAI).<br/>
</p>
    <b>Journal Reviewer:</b><br/> 
    IEEE Transactions on Pattern Analysis and Machine Intelligence.<br/>
    International Journal of Computer Vision.<br/>
    IEEE Transactions on Image Processing.<br/>
    Pattern Recognition.<br/>
</span>
</font>
</p>
<hr>

<h2> Activity</h2>
<p style = "margin-top:15px">
<font size=4>
<span style="color:black">
    <b>Academic Talk:</b><br/>
    "LLaMA-VID:An Image is Worth 2 Tokens in Large Language Models", MIT/Huawei/Tencent, 2023. [<a href="talk/LLaMA-VID.pdf" style="color:rgb(51, 156, 255)">slides</a>]<br/>
    "Representation for Multi-modality 3D Detection with Transformer", ZhiDongXi, 2022. [<a href="talk/unfied_3d_det.pdf" style="color:rgb(51, 156, 255)">slides</a>]<br/> 
    "Towards Fully Convolutional Panoptic Segmentation", ByteDance AI & BAAI, 2021. [<a href="talk/PanopticFCN-talk.pdf" style="color:rgb(51, 156, 255)">slides</a>]<br/> 
    "Dynamic Network and Semantic Segmentation", Paper Weekly, 2020. [<a href="talk/DynamicNet-and-SemanticSeg-talk.pdf" style="color:rgb(51, 156, 255)">slides</a>]<br/> 
    "FPN-based Network for Panoptic Segmentation", ECCV COCO Workshop, 2018. [<a href="talk/eccv2018-panoptic-talk-Pro.pdf" style="color:rgb(51, 156, 255)">slides</a>]<br/> 
</p>
    <b>Teaching Assistant:</b><br/>
    CSCI1580: Visual Programming, Fall, 2022.<br/>
    ENGG5104: Image Processing and Computer Vision, Spring, 2022.<br/>
    CSCI1580: Visual Programming, Fall, 2021.<br/>
    CSCI2100B: Data Structures, Spring, 2021.<br/>
</span>
</font>
</p>
<hr>

<h2> Award</h2>
<p style = "margin-top:15px">
<b><font size=4>
<span style="color:black">
Microsoft Fellowship Nomination, 2022<br/> 
Postgraduate Scholarship, 2020-2024<br/> 
National Scholarship, 2019<br/> 
National Scholarship, 2016<br/> 
</span>
</font></b>
</p>

<script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=5u9eqiy07hd&amp;m=7&amp;c=007eff&amp;cr1=00fff6&amp;f=arial&amp;l=33" async="async"></script>